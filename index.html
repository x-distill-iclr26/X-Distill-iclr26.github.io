<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>X-Distill: Project Page</title>
    <style>
        :root {
            --text-color: #333333;
            --title-color: #2c3e50;
            --link-color: #2980b9;
            --bg-color: #ffffff;
            --section-bg-color: #f8f9fa;
            --border-color: #dee2e6;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.7;
            color: var(--text-color);
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: var(--bg-color);
        }
        h1, h2, h3, h4 {
            color: var(--title-color);
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 10px;
            font-weight: 600;
        }
        h1 { font-size: 2.4em; letter-spacing: -1px; }
        h2 { font-size: 1.8em; margin-top: 50px; }
        h3 { font-size: 1.5em; border-bottom: none; margin-top: 40px;}
        h4 { font-size: 1.2em; border-bottom: none; margin-top: 30px; color: #555; text-align: left; padding-left: 10px; border-left: 3px solid var(--link-color);}
        a {
            color: var(--link-color);
            text-decoration: none;
            font-weight: 500;
        }
        a:hover {
            text-decoration: underline;
        }
        .paper-title {
            text-align: center;
            margin-bottom: 20px;
        }
        .paper-title p {
            font-size: 1.1em;
            color: #6c757d;
        }
        .links {
            text-align: center;
            font-size: 1.2em;
            margin-bottom: 40px;
            padding: 15px;
            background-color: var(--section-bg-color);
            border-radius: 8px;
        }
        .links a {
            margin: 0 15px;
        }
        .figure-container, .video-container {
            margin-bottom: 30px;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 15px;
            background-color: #fff;
            box-shadow: 0 2px 8px rgba(0,0,0,0.07);
        }
        .figure-container img, video {
            width: 100%;
            border-radius: 5px;
            background-color: #000;
        }
        .teaser-img {
            width: 100%;
            margin: 20px 0 40px 0;
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        #abstract {
            background-color: var(--section-bg-color);
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid var(--link-color);
            margin-bottom: 50px;
        }
        .caption {
            font-size: 0.95em;
            color: #555;
            margin-top: 10px;
            padding: 0 5px;
            text-align: left;
        }
        .footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 20px;
            font-size: 0.9em;
            color: #888;
            border-top: 1px solid var(--border-color);
        }
    </style>
</head>
<body>

    <div class="paper-title">
        <h1>X-Distill: Cross-Architecture Vision Distillation Enables Data-Efficient Visuomotor Learning</h1>
        <p>Anonymous ICLR 2026 Submission</p>
    </div>

    <div class="links">
        <a href="#abstract">[Abstract]</a>
        <a href="#real-world">[Real-World Experiments]</a>
        <a href="#analysis">[Qualitative Analysis]</a>
    </div>

    <img src="teaser_figure.png" alt="Teaser Figure" class="teaser-img">

    <h2 id="abstract">Abstract</h2>
    <p>
        Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly finetuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on 34 simulated benchmarks and 5 challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or finetuned DINOv2 encoders. Notably, X-Distill also surpasses stronger baselines that utilize privileged 3D observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.
    </p>

    <!-- 核心修改: 将 Task Setup 和 Videos 合并到一个 Section -->
    <h2 id="real-world">Real-World Experiments</h2>
    
    <h3>Task Setup & Generalization</h3>
    <div class="figure-container">
        <img src="path/to/your/realworld_config_figure.png" alt="Real-world task configurations">
        <p class="caption"><b>Visualization of configurations for our real-world tasks.</b> The green regions represent the distribution of object/robot configurations seen during training (In-Domain), while the red regions illustrate the novel configurations used for generalization testing (Out-of-Domain).</p>
    </div>

    <h3>Task-by-Task Video Results</h3>
    
    <h4>Task 1: Move Cube</h4>
    <div class="video-container">
        <video controls loop muted playsinline poster="cube_thumbnail.jpg">
            <source src="videos/move_cube_comparison.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <p class="caption"><b>4-Way Comparison:</b> A side-by-side comparison of all methods on the Move Cube task. Top-left: ResNet-scratch, Top-right: π₀ (SFT), Bottom-left: DINOv2, Bottom-right: <b>X-Distill (Ours)</b>.</p>
    </div>

    <h4>Task 2: Move Brush</h4>
    <div class="video-container">
        <video controls loop muted playsinline poster="brush_thumbnail.jpg">
            <source src="videos/move_brush_comparison.mp4" type="video/mp4"></video>
        <p class="caption"><b>4-Way Comparison:</b> Side-by-side performance on the Move Brush task.</p>
    </div>
    
    <h4>Task 3: Writing "AGI"</h4>
    <div class="video-container">
        <video controls loop muted playsinline poster="writing_thumbnail.jpg">
            <source src="videos/writing_agi_comparison.mp4" type="video/mp4"></video>
        <p class="caption"><b>4-Way Comparison:</b> Note the perseverative behavior of ResNet-scratch and the hesitation of DINOv2 and π₀.</p>
    </div>
    <div class="video-container">
        <video controls loop muted playsinline poster="perturb_thumbnail.jpg">
            <source src="videos/writing_perturb_comparison.mp4" type="video/mp4"></video>
        <p class="caption"><b>Robustness to Perturbation:</b> X-Distill (right) robustly adapts, while ResNet-scratch (left) fails.</p>
    </div>

    <h4>Task 4: Drawer Open</h4>
    <div class="video-container">
        <video controls loop muted playsinline poster="drawer_thumbnail.jpg">
            <source src="videos/drawer_open_comparison.mp4" type="video/mp4"></video>
        <p class="caption"><b>4-Way Comparison:</b> Performance on the Drawer Open task.</p>
    </div>
    
    <h4>Task 5: Door Close</h4>
    <div class="video-container">
        <video controls loop muted playsinline poster="door_thumbnail.jpg">
            <source src="videos/door_close_comparison.mp4" type="video/mp4"></video>
        <p class="caption"><b>4-Way Comparison:</b> Performance on the Door Close task.</p>
    </div>


    <h2 id="analysis">Qualitative Analysis</h2>
    
    <h3>Feature Space Separability (t-SNE)</h3>
    <div class="figure-container">
        <img src="path/to/your/tsne_visualization.png" alt="t-SNE visualization of learned feature spaces">
        <p class="caption"><b>t-SNE visualization of learned feature spaces on the "Writing AGI" task.</b> Our X-Distill encoder learns three well-separated clusters corresponding to the task's semantic stages (Silhouette Score: 0.472), while baselines fail to form a meaningful structure. This semantic separability is crucial for the policy to accurately identify the current task stage, enabling precise long-horizon planning.</p>
    </div>

    <h3>Saliency Map Visualization</h3>
    <div class="video-container">
        <video controls loop muted playsinline poster="saliency_thumbnail.jpg">
             <!-- 【重要】当您制作好热力图对比视频后，取消下面这行代码的注释 -->
            <!-- <source src="videos/saliency_map_comparison.mp4" type="video/mp4"> -->
        </video>
        <p class="caption"><b>(Coming Soon) 4-Way Saliency Map Comparison:</b> This video will show a side-by-side comparison of the visual attention for all four methods on the "Writing AGI" task, providing insight into why our model succeeds.</p>
    </div>

    <div class="footer">
        <p>ICLR 2026 Anonymous Submission</p>
    </div>

</body>
</html>

